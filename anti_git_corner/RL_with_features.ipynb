{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "from MDP import QLearningAlgorithm\n",
    "from MDP import TradeMDP\n",
    "import pandas as pd\n",
    "from features import *\n",
    "############################################################\n",
    "# Simulate the whole process for numTrial times\n",
    "# rl: the defined RL problem we have construct\n",
    "# Data: daily data or else\n",
    "# Mode: Only ! Sell ! and ! Buy ! available\n",
    "# Learn: Whether we are training. If we are testing, set to False\n",
    "def Simulate(rl, orderbooks_df,transaction_df,quantile_df, time_frame, FeatureNum, numTrial = 200, learn=True):\n",
    "\n",
    "    def buildOrder(remain, action, orderbook):\n",
    "        # Find the Action, we build the order (According to the Sects[0])\n",
    "        if action == 'MO':\n",
    "            Order = util.SellOrder(remain, action, orderbook)\n",
    "        else:\n",
    "            price = orderbook.ask_prices[0] - 0.01 * int(action)\n",
    "            Order = util.SellOrder(remain, price, orderbook)\n",
    "        return Order\n",
    "    \n",
    "    \n",
    "    def rank_calculation(func, orderbooks_df, quantile_df,transaction_df,need_transaction_df, *feature_name):\n",
    "        # calculate the rank of the feature \n",
    "        #length = len(feature_name)\n",
    "        feature_rank=[]\n",
    "\n",
    "        if need_transaction_df:\n",
    "            calculated_feature=func(orderbooks_df,transaction_df)\n",
    "        else:\n",
    "            calculated_feature=func(orderbooks_df)\n",
    "        for name in feature_name:\n",
    "            temp=float(calculated_feature[name].iloc[-1])\n",
    "            q1,q2=quantile_df[name].iloc[0],quantile_df[name].iloc[1]\n",
    "            rank = 1 if temp <= q1 else 2 if temp <= q2 else 3\n",
    "            feature_rank.append(rank)\n",
    "        \n",
    "        return feature_rank\n",
    "\n",
    "        \n",
    "    # Get the Reward and Newstate after taking action in Simulate with Sects\n",
    "    def ActEnv(rl, iter, volume, action, orderbooks, orderbooks_df, quantile_df):\n",
    "        # Build Order\n",
    "        order = buildOrder(volume, action, orderbooks[0])\n",
    "\n",
    "        # Simulate the Order\n",
    "        for orderbook in orderbooks[1:]:\n",
    "            #order.SimTrade(util.OrderBook(orderbook))\n",
    "            order.SimTrade(orderbook)\n",
    "        \n",
    "        remain = volume - order.fill\n",
    "\n",
    "        # Different Reward Calculate by Different Mode\n",
    "        reward = order.turnover - start_mid * order.fill\n",
    "        \n",
    "        #Notice that FeatureNum !=  feature function number\n",
    "        #feature function name:\n",
    "        #volatility,relative_mid_trend,illiquidity,volume_depth\n",
    "        \n",
    "        feature_name = quantile.columns.drop('Unnamed: 0')\n",
    "        \n",
    "        feature_rank=[]\n",
    "        feature_rank+=rank_calculation(volatility, orderbooks_df, quantile_df,transaction_df,False,feature_name[0] )\n",
    "        feature_rank+=rank_calculation(order_flow, orderbooks_df, quantile_df,transaction_df,True, *feature_name[1:])\n",
    "        \n",
    "        # Newstate Define\n",
    "        if iter == rl.mdp.timeLevel:\n",
    "            newState = None\n",
    "        else:\n",
    "            newState = rl.mdp.JudgeState([iter + 1, remain]+feature_rank)  \n",
    "        return reward, newState, remain, order\n",
    "\n",
    "    \n",
    "    orderbooks = orderbooks_df.loc[:time_frame].values\n",
    "    # Define the expected price\n",
    "    init = util.OrderBook(row=orderbooks[0])\n",
    "    start_mid = init.get_mid_price()\n",
    "    \n",
    "    # Get the list version of orderbook (instead of the dataframe version)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # When we simulate a buy process for numTrial time\n",
    "    for j in range(numTrial):\n",
    "        remain = rl.mdp.totalVol\n",
    "        state = rl.mdp.startState()\n",
    "        sequences = []\n",
    "\n",
    "        # Sects: a list contains series of orderbooks\n",
    "        for i in range(rl.mdp.timeLevel + 1):\n",
    "            #print(i)\n",
    "            if state is None:\n",
    "                #print('break')\n",
    "                break\n",
    "            if i == rl.mdp.timeLevel:\n",
    "                Sects = [util.OrderBook(row=orderbooks[-1])]\n",
    "            else:\n",
    "                ob_data = orderbooks[i*rl.mdp.timeGap: (i+1)*rl.mdp.timeGap]\n",
    "                Sects = [util.OrderBook(row=ob) for ob in ob_data]\n",
    "                Sects_df = orderbooks_df.iloc[i*rl.mdp.timeGap: (i+1)*rl.mdp.timeGap]\n",
    "            \n",
    "            \n",
    "            action = rl.getAction(state, learn)\n",
    "            \n",
    "            reward, newState, remain, pre_order = ActEnv(rl, iter=i, volume=remain, action=action,\n",
    "                                                         orderbooks=Sects,orderbooks_df=Sects_df,quantile_df=quantile)\n",
    "            #print(newState)\n",
    "            sequences.append((state, action, reward, newState))\n",
    "            state = newState\n",
    "            \n",
    "        # For update the QGrid, we update from the end to the start\n",
    "        #  (for updating while using the updating results before)\n",
    "        if learn:\n",
    "           \n",
    "            sequences.reverse()\n",
    "            for sequence in sequences:\n",
    "                state, action, reward, newState = sequence\n",
    "                #print(state)\n",
    "                rl.updateQ(state, action, reward, newState)\n",
    "                \n",
    "        else:\n",
    "            # We are testing, so return the reward\n",
    "            # Extract the reward for the sequence and sum up for the total reward in test\n",
    "            return sum([sequence[2] for sequence in sequences])\n",
    "\n",
    "        # Explore probability upgrade if learn!\n",
    "        rl.update_prob()\n",
    "\n",
    "        if j % 50 ==0:\n",
    "            print('This is the',j,'th iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "orderbooks= pd.read_csv(data_dir+'orderbook.csv')\n",
    "quantile=pd.read_csv(data_dir+\"ranked_features_test.csv\")\n",
    "transaction=pd.read_csv(data_dir+\"transaction.csv\")\n",
    "FeatureNum=len(quantile.columns)-1\n",
    "timeGap = 1000 \n",
    "timeLevel=4\n",
    "total_time = timeLevel*timeGap  # timeframe\n",
    "\n",
    "mdp=TradeMDP(totalVol=10000,voLevel=5,timeLevel=timeLevel,priceFlex=3,timeGap=timeGap,FeatureLevel=3,FeatureNum=FeatureNum)\n",
    "\n",
    "q_algo=QLearningAlgorithm(mdp,100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vol', 'order_flow_buy', 'order_flow_sell', 'actual_spread',\n",
       "       'relative_spread', 'actual_mkt_imb', 'relative_mkt_imb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The feature names have to be put in simulation manually.\n",
    "quantile.columns.drop('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 0 th iteration\n",
      "This is the 50 th iteration\n",
      "This is the 100 th iteration\n",
      "This is the 150 th iteration\n"
     ]
    }
   ],
   "source": [
    "Simulate(q_algo,orderbooks,transaction,quantile,FeatureNum=2,time_frame=total_time,numTrial =200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-149.9129999999904"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Simulate(q_algo,orderbooks,transaction,quantile,FeatureNum=2,time_frame=total_time,numTrial =200,learn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
